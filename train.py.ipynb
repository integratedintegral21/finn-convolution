{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:21:10.542186Z",
     "start_time": "2024-07-27T15:21:10.539503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: setuptools==69.5.0 in /tmp/home_dir/.local/lib/python3.10/site-packages (69.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools==69.5.0\n",
    "import datetime\n",
    "import torch\n",
    "import torchvision\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant.scaled_int import Int8ActPerTensorFloat, Int32Bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e030abee64f24243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:21:11.352482Z",
     "start_time": "2024-07-27T15:21:11.346618Z"
    }
   },
   "outputs": [],
   "source": [
    "WEIGHT_BIT_WIDTH = 8\n",
    "ACT_BIT_WIDTH = 3\n",
    "\n",
    "class QuantModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_0 = qnn.QuantConv2d(\n",
    "            1,\n",
    "            6,\n",
    "            kernel_size=3,\n",
    "            bias=False,\n",
    "            weight_bit_width=WEIGHT_BIT_WIDTH)\n",
    "        self.relu_0 = qnn.QuantReLU(bit_width=ACT_BIT_WIDTH)\n",
    "        self.conv_1 = qnn.QuantConv2d(6, 16, 6,\n",
    "                                      weight_bit_width=WEIGHT_BIT_WIDTH,\n",
    "                                      bias=False)\n",
    "        self.relu_1 = qnn.QuantReLU(bit_width=ACT_BIT_WIDTH)\n",
    "        self.conv_2 = qnn.QuantConv2d(16, 128, 4,\n",
    "                                      weight_bit_width=WEIGHT_BIT_WIDTH,\n",
    "                                      bias=False)\n",
    "        self.fc1 = qnn.QuantLinear(128, 84,\n",
    "                                   weight_bit_width=WEIGHT_BIT_WIDTH,\n",
    "                                   bias=True)\n",
    "        self.relu_2 = qnn.QuantReLU(bit_width=ACT_BIT_WIDTH)\n",
    "        self.fc2 = qnn.QuantLinear(84, 10,\n",
    "                                   weight_bit_width=WEIGHT_BIT_WIDTH,\n",
    "                                   bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_0(x)\n",
    "        x = self.relu_0(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2, 2)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2, 2)\n",
    "        x = self.conv_2(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f1fb149c27aef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:21:12.137494Z",
     "start_time": "2024-07-27T15:21:12.134802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895c6d91687a802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:21:13.396027Z",
     "start_time": "2024-07-27T15:21:13.392950Z"
    }
   },
   "outputs": [],
   "source": [
    "input_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88205ae5d68494ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:21:14.254806Z",
     "start_time": "2024-07-27T15:21:14.156238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  60000\n",
      "Val dataset size:  10000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST('./data', train=True, download=True, transform=input_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset = torchvision.datasets.FashionMNIST('./data', train=False, download=True, transform=input_transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "print(\"Train dataset size: \", len(train_dataset))\n",
    "print(\"Val dataset size: \", len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8075071867491929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:21:15.114310Z",
     "start_time": "2024-07-27T15:21:15.086475Z"
    }
   },
   "outputs": [],
   "source": [
    "model = QuantModel().to(device)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f17c9e4cc6dd0bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:26:26.300125Z",
     "start_time": "2024-07-27T15:21:16.385219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Batch 100: Train loss: 2.326232163906097\n",
      "Batch 200: Train loss: 2.2999991583824158\n",
      "Batch 300: Train loss: 2.296544842720032\n",
      "Batch 400: Train loss: 2.2940742707252504\n",
      "Batch 500: Train loss: 2.2860090065002443\n",
      "Batch 600: Train loss: 2.2772892189025877\n",
      "Batch 700: Train loss: 2.260222737789154\n",
      "Batch 800: Train loss: 2.232508268356323\n",
      "Batch 900: Train loss: 2.1825063848495483\n",
      "Val loss: 2.115875739200859\n",
      "Epoch 1\n",
      "Batch 100: Train loss: 2.080527250766754\n",
      "Batch 200: Train loss: 1.905735763311386\n",
      "Batch 300: Train loss: 1.732987620830536\n",
      "Batch 400: Train loss: 1.5567605876922608\n",
      "Batch 500: Train loss: 1.3984897255897522\n",
      "Batch 600: Train loss: 1.268468418121338\n",
      "Batch 700: Train loss: 1.1667830550670624\n",
      "Batch 800: Train loss: 1.1032745975255966\n",
      "Batch 900: Train loss: 1.0356007397174836\n",
      "Val loss: 1.0123573389782268\n",
      "Epoch 2\n",
      "Batch 100: Train loss: 0.9851358270645142\n",
      "Batch 200: Train loss: 0.9386532229185104\n",
      "Batch 300: Train loss: 0.9216842442750931\n",
      "Batch 400: Train loss: 0.8831329649686813\n",
      "Batch 500: Train loss: 0.8879271709918976\n",
      "Batch 600: Train loss: 0.8524661201238632\n",
      "Batch 700: Train loss: 0.8177202612161636\n",
      "Batch 800: Train loss: 0.8052940785884857\n",
      "Batch 900: Train loss: 0.7799860692024231\n",
      "Val loss: 0.7906665456522802\n",
      "Epoch 3\n",
      "Batch 100: Train loss: 0.7786542183160782\n",
      "Batch 200: Train loss: 0.7618011748790741\n",
      "Batch 300: Train loss: 0.7360293263196945\n",
      "Batch 400: Train loss: 0.7189247012138367\n",
      "Batch 500: Train loss: 0.7038301059603691\n",
      "Batch 600: Train loss: 0.6998315015435219\n",
      "Batch 700: Train loss: 0.6850284332036972\n",
      "Batch 800: Train loss: 0.6688992440700531\n",
      "Batch 900: Train loss: 0.6763692972064018\n",
      "Val loss: 0.6800416265703311\n",
      "Epoch 4\n",
      "Batch 100: Train loss: 0.6749852547049522\n",
      "Batch 200: Train loss: 0.6444404697418213\n",
      "Batch 300: Train loss: 0.6629457014799118\n",
      "Batch 400: Train loss: 0.6525110030174255\n",
      "Batch 500: Train loss: 0.6252985674142838\n",
      "Batch 600: Train loss: 0.6130005851387977\n",
      "Batch 700: Train loss: 0.6125615602731704\n",
      "Batch 800: Train loss: 0.5945917516946793\n",
      "Batch 900: Train loss: 0.5928981333971024\n",
      "Val loss: 0.6251797510939798\n",
      "Epoch 5\n",
      "Batch 100: Train loss: 0.60288221180439\n",
      "Batch 200: Train loss: 0.5779721519351005\n",
      "Batch 300: Train loss: 0.5877146509289741\n",
      "Batch 400: Train loss: 0.5974010989069939\n",
      "Batch 500: Train loss: 0.5547269427776337\n",
      "Batch 600: Train loss: 0.5708225193619728\n",
      "Batch 700: Train loss: 0.5713413512706756\n",
      "Batch 800: Train loss: 0.5616081163287163\n",
      "Batch 900: Train loss: 0.5533873203396797\n",
      "Val loss: 0.5687808578561067\n",
      "Epoch 6\n",
      "Batch 100: Train loss: 0.5531377184391022\n",
      "Batch 200: Train loss: 0.5451231959462166\n",
      "Batch 300: Train loss: 0.5545656499266625\n",
      "Batch 400: Train loss: 0.561474367082119\n",
      "Batch 500: Train loss: 0.5058702671527863\n",
      "Batch 600: Train loss: 0.5283497938513756\n",
      "Batch 700: Train loss: 0.5272115942835808\n",
      "Batch 800: Train loss: 0.5227193820476532\n",
      "Batch 900: Train loss: 0.5295617064833641\n",
      "Val loss: 0.5542325933647764\n",
      "Epoch 7\n",
      "Batch 100: Train loss: 0.5315369442105293\n",
      "Batch 200: Train loss: 0.4908056965470314\n",
      "Batch 300: Train loss: 0.5209869626164436\n",
      "Batch 400: Train loss: 0.49692464619874954\n",
      "Batch 500: Train loss: 0.505008417069912\n",
      "Batch 600: Train loss: 0.5062044453620911\n",
      "Batch 700: Train loss: 0.5129781991243363\n",
      "Batch 800: Train loss: 0.4923575584590435\n",
      "Batch 900: Train loss: 0.5150113669037819\n",
      "Val loss: 0.5173136958271075\n",
      "Epoch 8\n",
      "Batch 100: Train loss: 0.4975148245692253\n",
      "Batch 200: Train loss: 0.49757100254297254\n",
      "Batch 300: Train loss: 0.48989757865667344\n",
      "Batch 400: Train loss: 0.4833230398595333\n",
      "Batch 500: Train loss: 0.4769972011446953\n",
      "Batch 600: Train loss: 0.4962380638718605\n",
      "Batch 700: Train loss: 0.4893332239985466\n",
      "Batch 800: Train loss: 0.46921239376068113\n",
      "Batch 900: Train loss: 0.47100502729415894\n",
      "Val loss: 0.48578513940428475\n",
      "Epoch 9\n",
      "Batch 100: Train loss: 0.48636458039283753\n",
      "Batch 200: Train loss: 0.4655643589794636\n",
      "Batch 300: Train loss: 0.46091256886720655\n",
      "Batch 400: Train loss: 0.47337546184659\n",
      "Batch 500: Train loss: 0.43893270939588547\n",
      "Batch 600: Train loss: 0.4539553180336952\n",
      "Batch 700: Train loss: 0.4776767560839653\n",
      "Batch 800: Train loss: 0.453904659897089\n",
      "Batch 900: Train loss: 0.4648463347554207\n",
      "Val loss: 0.4760784107218882\n",
      "Epoch 10\n",
      "Batch 100: Train loss: 0.44720835641026496\n",
      "Batch 200: Train loss: 0.439324858635664\n",
      "Batch 300: Train loss: 0.44278375640511514\n",
      "Batch 400: Train loss: 0.4478658363223076\n",
      "Batch 500: Train loss: 0.4570122528076172\n",
      "Batch 600: Train loss: 0.451788113117218\n",
      "Batch 700: Train loss: 0.4287567365169525\n",
      "Batch 800: Train loss: 0.4460128574073315\n",
      "Batch 900: Train loss: 0.44499883383512495\n",
      "Val loss: 0.4600363286437502\n",
      "Epoch 11\n",
      "Batch 100: Train loss: 0.44140534281730653\n",
      "Batch 200: Train loss: 0.4292690019309521\n",
      "Batch 300: Train loss: 0.443570499420166\n",
      "Batch 400: Train loss: 0.4253947906196117\n",
      "Batch 500: Train loss: 0.4214479574561119\n",
      "Batch 600: Train loss: 0.43279374107718466\n",
      "Batch 700: Train loss: 0.4278977464139462\n",
      "Batch 800: Train loss: 0.4359941631555557\n",
      "Batch 900: Train loss: 0.41441049337387087\n",
      "Val loss: 0.4407182747771026\n",
      "Epoch 12\n",
      "Batch 100: Train loss: 0.41884978860616684\n",
      "Batch 200: Train loss: 0.4206260934472084\n",
      "Batch 300: Train loss: 0.40985126614570616\n",
      "Batch 400: Train loss: 0.39448962643742563\n",
      "Batch 500: Train loss: 0.41829595908522604\n",
      "Batch 600: Train loss: 0.4200749123096466\n",
      "Batch 700: Train loss: 0.4139239825308323\n",
      "Batch 800: Train loss: 0.4082120975852013\n",
      "Batch 900: Train loss: 0.4136073268949986\n",
      "Val loss: 0.41840397571302523\n",
      "Epoch 13\n",
      "Batch 100: Train loss: 0.4111091521382332\n",
      "Batch 200: Train loss: 0.3877958261966705\n",
      "Batch 300: Train loss: 0.4054005591571331\n",
      "Batch 400: Train loss: 0.4199782025814056\n",
      "Batch 500: Train loss: 0.39520568877458573\n",
      "Batch 600: Train loss: 0.4178636382520199\n",
      "Batch 700: Train loss: 0.41393287301063536\n",
      "Batch 800: Train loss: 0.3781412079930305\n",
      "Batch 900: Train loss: 0.37141553446650505\n",
      "Val loss: 0.43220716895191535\n",
      "Epoch 14\n",
      "Batch 100: Train loss: 0.4074759252369404\n",
      "Batch 200: Train loss: 0.38578265309333803\n",
      "Batch 300: Train loss: 0.3926098354160786\n",
      "Batch 400: Train loss: 0.3878685538470745\n",
      "Batch 500: Train loss: 0.38411775514483454\n",
      "Batch 600: Train loss: 0.3868834997713566\n",
      "Batch 700: Train loss: 0.3889974845945835\n",
      "Batch 800: Train loss: 0.390934603959322\n",
      "Batch 900: Train loss: 0.3910826000571251\n",
      "Val loss: 0.39802772774817835\n",
      "Epoch 15\n",
      "Batch 100: Train loss: 0.3808035832643509\n",
      "Batch 200: Train loss: 0.3744989024102688\n",
      "Batch 300: Train loss: 0.373653504550457\n",
      "Batch 400: Train loss: 0.3765876713395119\n",
      "Batch 500: Train loss: 0.38751678362488745\n",
      "Batch 600: Train loss: 0.38135738343000414\n",
      "Batch 700: Train loss: 0.3822869709134102\n",
      "Batch 800: Train loss: 0.38588547870516776\n",
      "Batch 900: Train loss: 0.3828173740208149\n",
      "Val loss: 0.3914073674352306\n",
      "Epoch 16\n",
      "Batch 100: Train loss: 0.38090265199542045\n",
      "Batch 200: Train loss: 0.3601840259134769\n",
      "Batch 300: Train loss: 0.3748268820345402\n",
      "Batch 400: Train loss: 0.36129663705825804\n",
      "Batch 500: Train loss: 0.3756961865723133\n",
      "Batch 600: Train loss: 0.3758382421731949\n",
      "Batch 700: Train loss: 0.3724415637552738\n",
      "Batch 800: Train loss: 0.3846567234396934\n",
      "Batch 900: Train loss: 0.3695787635445595\n",
      "Val loss: 0.39879639418261825\n",
      "Epoch 17\n",
      "Batch 100: Train loss: 0.3630274070799351\n",
      "Batch 200: Train loss: 0.36047893315553664\n",
      "Batch 300: Train loss: 0.36954216882586477\n",
      "Batch 400: Train loss: 0.35984177261590955\n",
      "Batch 500: Train loss: 0.35453383907675745\n",
      "Batch 600: Train loss: 0.3788697877526283\n",
      "Batch 700: Train loss: 0.3653208197653294\n",
      "Batch 800: Train loss: 0.3520617350935936\n",
      "Batch 900: Train loss: 0.3621233268082142\n",
      "Val loss: 0.3918146642909688\n",
      "Epoch 18\n",
      "Batch 100: Train loss: 0.35551489308476447\n",
      "Batch 200: Train loss: 0.35858436569571495\n",
      "Batch 300: Train loss: 0.3600562320649624\n",
      "Batch 400: Train loss: 0.3567040856182575\n",
      "Batch 500: Train loss: 0.3656023606657982\n",
      "Batch 600: Train loss: 0.3759823839366436\n",
      "Batch 700: Train loss: 0.34700183287262915\n",
      "Batch 800: Train loss: 0.35914008304476736\n",
      "Batch 900: Train loss: 0.36151378765702247\n",
      "Val loss: 0.3819116452696976\n",
      "Epoch 19\n",
      "Batch 100: Train loss: 0.35280941173434255\n",
      "Batch 200: Train loss: 0.3466895169019699\n",
      "Batch 300: Train loss: 0.3505083780735731\n",
      "Batch 400: Train loss: 0.3703575038909912\n",
      "Batch 500: Train loss: 0.3417140290141106\n",
      "Batch 600: Train loss: 0.3443817898631096\n",
      "Batch 700: Train loss: 0.3455447617173195\n",
      "Batch 800: Train loss: 0.3633011162281036\n",
      "Batch 900: Train loss: 0.35421364799141886\n",
      "Val loss: 0.3788851598265824\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss_value = loss(outputs, labels)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss_value.item()\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            last_loss = train_loss / 100\n",
    "            print(f\"Batch {i}: Train loss: {last_loss}\")\n",
    "            train_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss_value = loss(outputs, labels)\n",
    "            val_loss += loss_value.item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Val loss: {val_loss}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"fashion_mnist_quant.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec824f8a5a7a7587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:27:13.278896Z",
     "start_time": "2024-07-27T15:27:13.263897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"fashion_mnist_quant.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9ecafb87dcb543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T15:30:53.933630Z",
     "start_time": "2024-07-27T15:30:53.555184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 98] Address already in use",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m qonnx_cleanup(qonnx_path, out_file\u001b[38;5;241m=\u001b[39mqonnx_path)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m showInNetron\n\u001b[0;32m---> 16\u001b[0m \u001b[43mshowInNetron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqonnx_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/wojciech/finn-examples/build/finn/src/finn/util/visualization.py:61\u001b[0m, in \u001b[0;36mshowInNetron\u001b[0;34m(model_filename, localhost_url, port)\u001b[0m\n\u001b[1;32m     59\u001b[0m     port \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8081\u001b[39m\n\u001b[1;32m     60\u001b[0m localhost_url \u001b[38;5;241m=\u001b[39m localhost_url \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOCALHOST_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m \u001b[43mnetron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrowse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m IFrame(src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocalhost_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/netron/server.py:326\u001b[0m, in \u001b[0;36mstart\u001b[0;34m(file, address, browse, verbosity)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, browse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    315\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Start serving model file at address and open in web browser.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m        A (host, port) address tuple.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrowse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrowse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/netron/server.py:303\u001b[0m, in \u001b[0;36mserve\u001b[0;34m(file, data, address, browse, verbosity)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     address \u001b[38;5;241m=\u001b[39m _make_port(address)\n\u001b[0;32m--> 303\u001b[0m thread \u001b[38;5;241m=\u001b[39m \u001b[43m_HTTPServerThread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m thread\u001b[38;5;241m.\u001b[39malive():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/netron/server.py:134\u001b[0m, in \u001b[0;36m_HTTPServerThread.__init__\u001b[0;34m(self, content, address, verbosity)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress \u001b[38;5;241m=\u001b[39m address\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m address[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(address[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver \u001b[38;5;241m=\u001b[39m \u001b[43m_ThreadedHTTPServer\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_HTTPRequestHandler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mtimeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mblock_on_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socketserver.py:452\u001b[0m, in \u001b[0;36mTCPServer.__init__\u001b[0;34m(self, server_address, RequestHandlerClass, bind_and_activate)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bind_and_activate:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_activate()\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/server.py:137\u001b[0m, in \u001b[0;36mHTTPServer.server_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserver_bind\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override server_bind to store the server name.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[43msocketserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTCPServer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     host, port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_address[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_name \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mgetfqdn(host)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socketserver.py:466\u001b[0m, in \u001b[0;36mTCPServer.server_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_reuse_address:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mSOL_SOCKET, socket\u001b[38;5;241m.\u001b[39mSO_REUSEADDR, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_address \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mgetsockname()\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 98] Address already in use"
     ]
    }
   ],
   "source": [
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "input_shape = (1, 1, 28, 28)\n",
    "inp = torch.rand(input_shape)\n",
    "print(next(val_loader.__iter__())[0].shape)\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "qonnx_path = \"fashion_mnist_quant.onnx\"\n",
    "export_qonnx(model, inp, export_path=qonnx_path)\n",
    "qonnx_cleanup(qonnx_path, out_file=qonnx_path)\n",
    "\n",
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(qonnx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa268e9d9113232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wojciech/finn-examples/build/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 14. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "finn_path = \"fashion_mnist_finn.onnx\"\n",
    "\n",
    "model_for_finn = ModelWrapper(qonnx_path)\n",
    "model_for_finn = model_for_finn.transform(ConvertQONNXtoFINN())\n",
    "model_for_finn.save(finn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69d5fe56-5171-4d09-9164-edf5571bde96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'fashion_mnist_finn.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x720eba1836d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0307957-4271-4c39-b0ce-67ae0726dbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINN output: [[-2.390639   -4.6819415  -3.6313727  -1.5422814  -3.9852936   3.3341618\n",
      "  -4.3270936   6.643266    0.62800026  9.485837  ]]\n",
      "Brevitas output: tensor([[-2.3906, -4.6819, -3.6314, -1.5423, -3.9853,  3.3342, -4.3271,  6.6433,\n",
      "          0.6280,  9.4858]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import numpy as np\n",
    "\n",
    "finn_path = \"fashion_mnist_finn.onnx\"\n",
    "\n",
    "model_for_finn = ModelWrapper(finn_path)\n",
    "input_name = model_for_finn.graph.input[0].name\n",
    "input_shape = model_for_finn.get_tensor_shape(input_name)\n",
    "output_name = model_for_finn.graph.output[0].name\n",
    "inp = next(val_loader.__iter__())[0][0:1]\n",
    "inp_dict = {input_name: inp.detach().numpy()}\n",
    "out_dict = oxe.execute_onnx(model_for_finn, inp_dict)\n",
    "\n",
    "print(f\"FINN output: {out_dict[output_name]}\")\n",
    "print(f\"Brevitas output: {model(inp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a71ce3-b888-4e48-b5c7-3e4f4b63342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wojciech/finn-examples/build/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "finn_path = \"fashion_mnist_finn.onnx\"\n",
    "\n",
    "model = ModelWrapper(finn_path)\n",
    "input_name = model.graph.input[0].name\n",
    "scale_inp = ToTensor()\n",
    "pre_ckpt = \"scale_input.onnx\"\n",
    "\n",
    "input_shape = (1, 1, 28, 28)\n",
    "inp = torch.rand(input_shape)\n",
    "export_qonnx(scale_inp, inp, export_path=pre_ckpt)\n",
    "qonnx_cleanup(pre_ckpt, out_file=pre_ckpt)\n",
    "\n",
    "pre_model = ModelWrapper(pre_ckpt)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "model.save(finn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c7ac4cf-054f-4baa-8da3-a94161033dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'fashion_mnist_finn.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x720eb740bfa0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(finn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc6d7880-7eb2-4041-82b4-624b49d69d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINN output: [[-2.390639   -4.6819415  -3.6313727  -1.5422814  -3.9852936   3.3341618\n",
      "  -4.3270936   6.643266    0.62800026  9.485837  ]]\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(finn_path)\n",
    "inp = next(val_loader.__iter__())[0][0:1] * 255\n",
    "np.save(\"test_inp.npy\", inp.swapaxes(1, -1))\n",
    "\n",
    "input_name = model_for_finn.graph.input[0].name\n",
    "inp_dict = {input_name: inp.detach().numpy()}\n",
    "\n",
    "out_dict = oxe.execute_onnx(model, inp_dict)\n",
    "output_name = model.graph.output[0].name\n",
    "print(f\"FINN output: {out_dict[output_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc0de08-8edd-4243-8f39-79f65029f315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
